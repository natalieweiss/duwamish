{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This script takes a path to a folder containing results from F&B and the name of the sampling outing \n",
    "## Note: All results must be in .xlsx format in order to be read by the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_levels(df):\n",
    "    df.reset_index(inplace = True)\n",
    "    df.columns = df.columns.droplevel(1)\n",
    "    return df\n",
    "\n",
    "def clean_pcb(val):\n",
    "    if 'aroclor' in val:\n",
    "        val = val\n",
    "    elif 'PCB' in val:\n",
    "        val = val.replace(\"/\",\" \").split(\" \")[1]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate file paths\n",
    "sample_outing_name = 'feb24_add'\n",
    "folder_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2024.2 add\"\n",
    "qaqc_path = f\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling Results/qaqc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initate folder paths for data to read in\n",
    "sl_path = f\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling Results/Lookup Tables/Master_Screening_Levels.xlsx\"\n",
    "pcb_arc_lookup_path = f\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling Results/Lookup Tables/PCB_aroclor_lookup.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder containing spreadsheets from F & B\n",
    "output_results_path = f\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/{sample_outing_name}_results.csv\"\n",
    "qaqc_results_path = f\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/qaqc/{sample_outing_name}_qaqc.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS RESULTS SPREADSHEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extension = '*.xlsx'\n",
    "\n",
    "# List all files with the specified extension in the folder\n",
    "files = glob.glob(os.path.join(folder_path, file_extension))\n",
    "\n",
    "results_df = []\n",
    "file_path = []\n",
    "records = []\n",
    "sample_ids = []\n",
    "methods = []\n",
    "\n",
    "# Iterate through each file and read its content\n",
    "for file in files:\n",
    "    df = pd.read_excel(file)\n",
    "    df.columns = df.columns.str.replace(\"_\",\" \")\n",
    "    results_df.append(df)\n",
    "\n",
    "    try:\n",
    "        # write out file paths, length of data frame, and sample IDs for qa / qc\n",
    "        sample_ids.append(list(df['Sample ID'].unique()))\n",
    "        file_path.append(file)\n",
    "        records.append(len(df))\n",
    "        methods.append(list(df['Result Method'].unique()))\n",
    "    except:\n",
    "        print(file)\n",
    "\n",
    "results_df = pd.concat(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "qaqc = {'file_path': file_path, 'records': records, 'sample_ids': sample_ids, 'method': methods}\n",
    "qaqc_df = pd.DataFrame(data = qaqc)\n",
    "qaqc_df.to_csv(qaqc_results_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any rows that were not field data\n",
    "results_df =  results_df[results_df['Field Collection Start Date'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column of sample type based on sample matrix and sample source columns\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Matrix']=='Aqueous', 'Water', results_df['Sample Matrix'])\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Matrix'].str.contains('Solid'), 'Soil', results_df['Sample Matrix_clean'])\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Source']=='Groundwater', 'Water', results_df['Sample Matrix_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up pcb values in order to make the join correctly with F&B results\n",
    "results_df['Result Parameter Name_clean'] = results_df['Result Parameter Name'].apply(lambda x: clean_fun(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Lube Oil to Diesel Range Organics\n",
    "results_df['Result Parameter Name_clean'] = np.where(results_df['Result Parameter Name_clean'] == 'Lube Oil', 'Diesel Range Organics', results_df['Result Parameter Name_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trailing spaces in sample id\n",
    "results_df['Sample ID'] = results_df['Sample ID'].str.strip()\n",
    "\n",
    "# change sample ID DPS1 -> DPS-1\n",
    "results_df['Sample ID'] = np.where(results_df['Sample ID'] == 'DPS1', 'DPS-1', results_df['Sample ID'])\n",
    "\n",
    "# change sample ID SPB-0159-S-1 -> SPB-O159-S-1\n",
    "results_df['Sample ID'] = np.where(results_df['Sample ID'] == 'SPB-0159-S-1', 'SPB-O159-S-1', results_df['Sample ID'])\n",
    "\n",
    "# replace typo from 11/17 -> 11/07\n",
    "results_df['Field Collection Start Date'] = np.where(results_df['Field Collection Start Date']=='2023-11-17 00:00:00', np.datetime64('2023-11-07'), results_df['Field Collection Start Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total PCBs for epa1668\n",
    "tot_pcbs = results_df[results_df['Result Method'] == 'EPA1668C']\n",
    "tot_pcbs = tot_pcbs.groupby(by =['Sample ID', 'Field Collection Start Date', 'Sample Matrix', 'Sample Matrix_clean','Result Value Units']).agg({'Result Value': ['sum']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_levels(tot_pcbs)\n",
    "tot_pcbs['Result Parameter Name_clean'] = 'Total PCBs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([results_df, tot_pcbs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns from raw data\n",
    "results_df = results_df[['Sample ID','Field Collection Start Date','Sample Matrix_clean','Sample Matrix','Sample Source',\n",
    "                         'Result Parameter Name','Result Parameter Name_clean','Result Value', 'Result Value Units', 'Result Reporting Limit', \n",
    "                         'Result Reporting Limit Type', 'Result Detection Limit','Result Detection Limit Type', 'Result Data Qualifier', 'Result Method']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(output_results_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
