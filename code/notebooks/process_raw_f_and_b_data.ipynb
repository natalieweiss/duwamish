{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This script takes a path to a folder containing results from F&B and the name of the sampling outing \n",
    "## Note: All results must be in .xlsx format in order to be read by the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate file paths\n",
    "sample_outing_name = 'feb24_add'\n",
    "folder_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2024.2 add\"\n",
    "qaqc_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling Results/qaqc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initate folder paths for data to read in\n",
    "sample_pts_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/Lookup Tables/Sampling_Sites_MASTER.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder containing spreadsheets from F & B\n",
    "output_results_path = f\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/{sample_outing_name}_results.csv\"\n",
    "qaqc_results_path = f\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/qaqc/{sample_outing_name}_qaqc.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS RESULTS SPREADSHEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_levels(df):\n",
    "    df.reset_index(inplace = True)\n",
    "    df.columns = df.columns.droplevel(1)\n",
    "    return df\n",
    "\n",
    "def clean_pcb(val):\n",
    "    if 'aroclor' in val:\n",
    "        val = val\n",
    "    elif 'PCB' in val:\n",
    "        val = val.replace(\"/\",\" \").split(\" \")[1]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extension = '*.xlsx'\n",
    "\n",
    "# List all files with the specified extension in the folder\n",
    "files = glob.glob(os.path.join(folder_path, file_extension))\n",
    "\n",
    "results_df = []\n",
    "file_path = []\n",
    "records = []\n",
    "sample_ids = []\n",
    "methods = []\n",
    "\n",
    "# Iterate through each file and read its content\n",
    "for file in files:\n",
    "    df = pd.read_excel(file, sheet_name = 'Sheet1')\n",
    "    df.columns = df.columns.str.replace(\"_\",\" \")\n",
    "    results_df.append(df)\n",
    "\n",
    "    try:\n",
    "        # write out file paths, length of data frame, and sample IDs for qa / qc\n",
    "        sample_ids.append(list(df['Sample ID'].unique()))\n",
    "        file_path.append(file)\n",
    "        records.append(len(df))\n",
    "        methods.append(list(df['Result Method'].unique()))\n",
    "    except:\n",
    "        print(file)\n",
    "\n",
    "results_df = pd.concat(results_df)\n",
    "results_df['Sample ID'] = results_df['Sample ID'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match found: 0_20879_OPR001\n",
      "No match found: Method Blank B9084_20879\n",
      "Match found: EAO-1-S-1\n"
     ]
    }
   ],
   "source": [
    "#### QAQC check to make sure that the sample ids match what is in our sampling sites spreadsheet\n",
    "sample_pts_gdf = gp.read_file(sample_pts_path)\n",
    "sample_pt_ids = sample_pts_gdf['Sampling ID'].unique()\n",
    "for f_b_ids in sample_ids:\n",
    "    for f_b_id in f_b_ids:\n",
    "        if f_b_id in sample_pt_ids: # check to see if f and b id is found in our master sampling sites\n",
    "            print(\"Match found:\", f_b_id)\n",
    "        else:\n",
    "            print(\"No match found:\", f_b_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### If an ID from F&B does not match the sampling sites id, replace the sample id here using this syntax\n",
    "# change sample ID DPS1 -> DPS-1\n",
    "results_df['Sample ID'] = np.where(results_df['Sample ID'] == 'DPS1', 'DPS-1', results_df['Sample ID'])\n",
    "\n",
    "# change sample ID SPB-0159-S-1 -> SPB-O159-S-1\n",
    "results_df['Sample ID'] = np.where(results_df['Sample ID'] == 'SPB-0159-S-1', 'SPB-O159-S-1', results_df['Sample ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/08/2023\n",
      "12/5/2023\n",
      "11/1/2023\n",
      "6/19/2023\n",
      "11/07/2023\n",
      "8/8/2023\n",
      "12/6/2023\n",
      "7/24/2023\n",
      "7/27/2023\n",
      "7/12/2023\n",
      "9/26/2023\n",
      "1/18/2024\n",
      "1/21/2024\n",
      "2/10/2024\n",
      "2/16/2024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### QAQC check to make sure the dates line up\n",
    "sample_dates = sample_pts_gdf['Date'].unique()\n",
    "f_b_dates = results_df['Field Collection Start Date'].unique()\n",
    "for date in sample_dates:\n",
    "     print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### QAQC: if any dates are mismatched, replace below using the same syntax\n",
    "# replace typo from 11/17 -> 11/07\n",
    "results_df['Field Collection Start Date'] = np.where(results_df['Field Collection Start Date']=='2023-11-17 00:00:00', np.datetime64('2023-11-07'), results_df['Field Collection Start Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any rows that were not field data\n",
    "results_df =  results_df[results_df['Field Collection Start Date'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "qaqc = {'file_path': file_path, 'records': records, 'sample_ids': sample_ids, 'method': methods}\n",
    "qaqc_df = pd.DataFrame(data = qaqc)\n",
    "qaqc_df.to_csv(qaqc_results_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column of sample type based on sample matrix and sample source columns\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Matrix']=='Aqueous', 'Water', results_df['Sample Matrix'])\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Matrix'].str.contains('Solid'), 'Soil', results_df['Sample Matrix_clean'])\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Source']=='Groundwater', 'Water', results_df['Sample Matrix_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up pcb values in order to make the join correctly with screening levels\n",
    "results_df['Result Parameter Name_clean'] = results_df['Result Parameter Name'].apply(lambda x: clean_pcb(x))\n",
    "\n",
    "# clean up d/f results to join correctly with screening levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Lube Oil to Diesel Range Organics\n",
    "results_df['Result Parameter Name_clean'] = np.where(results_df['Result Parameter Name_clean'] == 'Lube Oil', 'Diesel Range Organics', results_df['Result Parameter Name_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total PCBs for epa1668\n",
    "tot_pcbs = results_df[results_df['Result Method'] == 'EPA1668C']\n",
    "tot_pcbs = tot_pcbs.groupby(by =['Sample ID', 'Field Collection Start Date', 'Sample Matrix', 'Sample Matrix_clean','Result Value Units']).agg({'Result Value': ['sum']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_levels(tot_pcbs)\n",
    "tot_pcbs['Result Parameter Name_clean'] = 'Total PCBs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([results_df, tot_pcbs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns from raw data\n",
    "results_df = results_df[['Sample ID','Field Collection Start Date','Sample Matrix_clean','Sample Matrix','Sample Source',\n",
    "                         'Result Parameter Name','Result Parameter Name_clean','Result Value', 'Result Value Units', 'Result Reporting Limit', \n",
    "                         'Result Reporting Limit Type', 'Result Detection Limit','Result Detection Limit Type', 'Result Data Qualifier', 'Result Method']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(output_results_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
