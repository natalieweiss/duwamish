{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate columns to keep in final dataframe\n",
    "soil_RCRA_cols = ['DATE', 'SAMP_ID', 'Arsenic', 'Barium', 'Cadmium', 'Chromium', 'Lead','Selenium', 'Silver', 'Mercury']\n",
    "water_RCRA_cols = ['DATE', 'SAMP_ID', 'Arsenic', 'Barium', 'Cadmium', 'Chromium', 'Lead', 'Selenium', 'Silver', 'Mercury (CVAFS)', 'Mercury (CVAA)']\n",
    "pah_cols = ['DATE','SAMP_ID','1-Methylnaphthalene', '2-Methylnaphthalene', 'Acenaphthene', 'Acenaphthylene', 'Anthracene', 'Benzo(a)anthracene', 'Benzo(a)pyrene', 'Benzo(b)fluoranthene', 'Benzo(g,h,i)perylene', 'Benzo(k)fluoranthene', 'Chrysene', 'Dibenz(a,h)anthracene', 'Fluoranthene', 'Fluorene', 'Indeno(1,2,3-cd)pyrene', 'Naphthalene', 'Phenanthrene', 'Pyrene', '2-Fluorobiphenyl (S) %', 'Terphenyl-d14 (S) %']\n",
    "soil_pcb_cols = ['DATE', 'SAMP_ID', 'PCB Isomer','Concentrations Detected (mg/Kg)']\n",
    "water_pcb_cols = ['DATE', 'SAMP_ID', 'PCB Isomer','Concentrations Detected (ug/L)']\n",
    "soil_dxf_cols = ['DATE', 'SAMP_ID', 'Analyte', 'Result (mg/Kg)']\n",
    "soil_dxf_teq_cols = ['DATE','SAMP_ID', 'Analyte', 'Result (ng/Kg)', 'UB (mg/kg)']\n",
    "water_dxf_cols = ['DATE', 'SAMP_ID', 'Analyte', 'Result (ug/L)']\n",
    "water_dxf_teq_cols = ['DATE','SAMP_ID', 'Analyte', 'Result (pg/L)', 'UB (ug/L)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty data frames to store collated results across all sampling dates\n",
    "# by medium and pollutant type\n",
    "soil_rcra = pd.DataFrame()\n",
    "water_rcra = pd.DataFrame()\n",
    "soil_pah = pd.DataFrame()\n",
    "water_pah = pd.DataFrame()\n",
    "soil_pcb = pd.DataFrame()\n",
    "water_pcb = pd.DataFrame()\n",
    "soil_dxf = pd.DataFrame()\n",
    "soil_dxf_teq = pd.DataFrame()\n",
    "water_dxf = pd.DataFrame()\n",
    "water_dxf_teq = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all files in the directory\n",
    "subfolder_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results\"\n",
    "\n",
    "# Use a list comprehension to get all .xlsx files in the subfolder\n",
    "results_files = [f for f in os.listdir(subfolder_path) if f.endswith(\".xlsx\")]\n",
    "results_files.remove(\"TEMPLATE_UPD.xlsx\")\n",
    "results_files.remove(\"S4 and S6 Screening Results_CLEAN.xlsx\") # this is processed separated in \"exceedance_processing.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 8 Sampling Event Screening Results_CLEAN.xlsx sheet found\n",
      "Data Entry and QA QC Log.xlsx no sheet\n",
      "Duwamish Puget Creek Screening Results_CLEAN.xlsx sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx no sheet\n",
      "Kellogg Island Screening Results_CLEAN.xlsx sheet found\n",
      "People's Park Screening Result_CLEAN.xlsx sheet found\n",
      "S4 Screening Results_CLEAN.xlsx sheet found\n"
     ]
    }
   ],
   "source": [
    "# soil rcra processing\n",
    "\n",
    "for i in results_files:\n",
    "    try:\n",
    "        soil_rcra8_df = pd.read_excel(subfolder_path+'/'+i, sheet_name = 'Soil RCRA8')\n",
    "        print(i , \"sheet found\")\n",
    "\n",
    "        soil_rcra8_df = soil_rcra8_df[1:]\n",
    "        soil_rcra8_df = soil_rcra8_df[soil_RCRA_cols]\n",
    "        soil_rcra8_df = soil_rcra8_df.melt(id_vars=['DATE','SAMP_ID'])\n",
    "        soil_rcra8_df['Result Value Units'] = 'mg/kg'\n",
    "        soil_rcra8_df['Sample Matrix'] = 'Soil'\n",
    "        soil_rcra= pd.concat([soil_rcra, soil_rcra8_df], ignore_index= True)\n",
    "    except:\n",
    "        print(i, \"no sheet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 8 Sampling Event Screening Results_CLEAN.xlsx no sheet\n",
      "Data Entry and QA QC Log.xlsx no sheet\n",
      "Duwamish Puget Creek Screening Results_CLEAN.xlsx sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx sheet found\n",
      "Kellogg Island Screening Results_CLEAN.xlsx no sheet\n",
      "People's Park Screening Result_CLEAN.xlsx sheet found\n",
      "S4 Screening Results_CLEAN.xlsx sheet found\n"
     ]
    }
   ],
   "source": [
    "# water rcra results\n",
    "for i in results_files:\n",
    "    try:\n",
    "        water_rcra8_df = pd.read_excel(subfolder_path+'/'+i, sheet_name = 'Water RCRA8')\n",
    "        print(i , \"sheet found\")\n",
    "        water_rcra8_df = water_rcra8_df[1:]\n",
    "        water_rcra8_df = water_rcra8_df[water_RCRA_cols]\n",
    "        water_rcra8_df = water_rcra8_df.melt(id_vars=['DATE','SAMP_ID'])\n",
    "        water_rcra8_df['Result Value Units'] = 'ug/L'\n",
    "        water_rcra8_df['Sample Matrix'] = 'Water'\n",
    "        water_rcra= pd.concat([water_rcra, water_rcra8_df], ignore_index= True)\n",
    "    except:\n",
    "        print(i, \"no sheet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 8 Sampling Event Screening Results_CLEAN.xlsx sheet found\n",
      "Data Entry and QA QC Log.xlsx no sheet found\n",
      "Duwamish Puget Creek Screening Results_CLEAN.xlsx sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx no sheet found\n",
      "Kellogg Island Screening Results_CLEAN.xlsx sheet found\n",
      "People's Park Screening Result_CLEAN.xlsx sheet found\n",
      "S4 Screening Results_CLEAN.xlsx sheet found\n"
     ]
    }
   ],
   "source": [
    "# soil pah results\n",
    "for i in results_files:\n",
    "    try:\n",
    "        soil_pah_df = pd.read_excel(subfolder_path+'/'+i, sheet_name = 'PAH Soils')\n",
    "        print(i , \"sheet found\")\n",
    "        soil_pah_df = soil_pah_df[1:]\n",
    "        soil_pah_df= soil_pah_df[pah_cols]\n",
    "        soil_pah_df = soil_pah_df.melt(id_vars=['DATE','SAMP_ID'])\n",
    "        soil_pah_df['Result Value Units'] = 'mg/kg'\n",
    "        soil_pah_df['Sample Matrix'] = 'Soil'\n",
    "        soil_pah = pd.concat([soil_pah, soil_pah_df], ignore_index= True)\n",
    "    except:\n",
    "        print(i, \"no sheet found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 8 Sampling Event Screening Results_CLEAN.xlsx no sheet found\n",
      "Data Entry and QA QC Log.xlsx no sheet found\n",
      "Duwamish Puget Creek Screening Results_CLEAN.xlsx sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx sheet found\n",
      "Kellogg Island Screening Results_CLEAN.xlsx no sheet found\n",
      "People's Park Screening Result_CLEAN.xlsx sheet found\n",
      "S4 Screening Results_CLEAN.xlsx sheet found\n"
     ]
    }
   ],
   "source": [
    "# water pah results\n",
    "for i in results_files:\n",
    "    try:\n",
    "        water_pah_df = pd.read_excel(subfolder_path+'/'+i, sheet_name = 'PAH Soil to Groundwater')\n",
    "        print(i , \"sheet found\")\n",
    "        water_pah_df = water_pah_df[1:]\n",
    "        water_pah_df= water_pah_df[pah_cols]\n",
    "        water_pah_df = water_pah_df.melt(id_vars=['DATE','SAMP_ID'])\n",
    "        water_pah_df['Result Value Units'] = 'ug/L'\n",
    "        water_pah_df['Sample Matrix'] = 'Water'\n",
    "        water_pah = pd.concat([water_pah, water_pah_df], ignore_index= True)\n",
    "    except:\n",
    "        print(i, \"no sheet found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 8 Sampling Event Screening Results_CLEAN.xlsx no sheet found\n",
      "Data Entry and QA QC Log.xlsx no sheet found\n",
      "Duwamish Puget Creek Screening Results_CLEAN.xlsx no sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx no sheet found\n",
      "Kellogg Island Screening Results_CLEAN.xlsx sheet found\n",
      "People's Park Screening Result_CLEAN.xlsx sheet found\n",
      "S4 Screening Results_CLEAN.xlsx sheet found\n"
     ]
    }
   ],
   "source": [
    "# soil pcb results\n",
    "for i in results_files:\n",
    "    try:\n",
    "        soil_pcb_df = pd.read_excel(subfolder_path+'/'+i, sheet_name = 'PCBs Soils')\n",
    "        print(i , \"sheet found\")\n",
    "        soil_pcb_df = soil_pcb_df[1:]\n",
    "        soil_pcb_df= soil_pcb_df[soil_pcb_cols]\n",
    "        soil_pcb_df = soil_pcb_df.melt(id_vars=['DATE','SAMP_ID','PCB Isomer'])\n",
    "        soil_pcb_df.drop(columns = 'variable', inplace = True)\n",
    "        soil_pcb_df.rename(columns = {\"PCB Isomer\": 'variable'}, inplace = True)\n",
    "        soil_pcb_df['Result Value Units'] = 'mg/kg'\n",
    "        soil_pcb_df['Sample Matrix'] = 'Soil'\n",
    "        soil_pcb = pd.concat([soil_pcb, soil_pcb_df], ignore_index= True)\n",
    "    except:\n",
    "        print(i, \"no sheet found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 8 Sampling Event Screening Results_CLEAN.xlsx no sheet found\n",
      "Data Entry and QA QC Log.xlsx no sheet found\n",
      "Duwamish Puget Creek Screening Results_CLEAN.xlsx no sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx no sheet found\n",
      "Kellogg Island Screening Results_CLEAN.xlsx no sheet found\n",
      "People's Park Screening Result_CLEAN.xlsx sheet found\n",
      "S4 Screening Results_CLEAN.xlsx sheet found\n"
     ]
    }
   ],
   "source": [
    "# water pcb results\n",
    "for i in results_files:\n",
    "\n",
    "    try:\n",
    "        water_pcb_df = pd.read_excel(subfolder_path+'/'+i, sheet_name = 'PCBs Waters')\n",
    "        print(i, \"sheet found\")\n",
    "\n",
    "        water_pcb_df = water_pcb_df[1:]\n",
    "\n",
    "        water_pcb_df= water_pcb_df[water_pcb_cols]\n",
    "        water_pcb_df = water_pcb_df.melt(id_vars=['DATE','SAMP_ID','PCB Isomer'])\n",
    "        water_pcb_df.drop(columns = 'variable', inplace = True)\n",
    "        water_pcb_df.rename(columns = {\"PCB Isomer\": 'variable'}, inplace = True)\n",
    "\n",
    "        water_pcb_df['Result Value Units'] = 'ug/L'\n",
    "        water_pcb_df['Sample Matrix'] = 'Water'\n",
    "        water_pcb = pd.concat([water_pcb, water_pcb_df], ignore_index= True)\n",
    "    except:\n",
    "        print(i, \"no sheet found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 8 Sampling Event Screening Results_CLEAN.xlsx no sheet found\n",
      "Data Entry and QA QC Log.xlsx no sheet found\n",
      "Duwamish Puget Creek Screening Results_CLEAN.xlsx sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx no sheet found\n",
      "Kellogg Island Screening Results_CLEAN.xlsx sheet found\n",
      "People's Park Screening Result_CLEAN.xlsx sheet found\n",
      "S4 Screening Results_CLEAN.xlsx sheet found\n"
     ]
    }
   ],
   "source": [
    "# soil dioxins and furans results\n",
    "for i in results_files:\n",
    "\n",
    "    try:\n",
    "        soil_dxf_df = pd.read_excel(subfolder_path+'/'+i, sheet_name = 'Dioxins and Furans Soils')\n",
    "        print(i, \"sheet found\")\n",
    "\n",
    "        soil_dxf_df = soil_dxf_df[soil_dxf_cols]\n",
    "        soil_dxf_df.rename(columns = {\"Analyte\": 'variable', \"Result (mg/Kg)\":\"value\"}, inplace = True)\n",
    "        soil_dxf_df['Result Value Units'] = 'mg/kg'\n",
    "        soil_dxf_df['Sample Matrix'] = 'Soil'\n",
    "        soil_dxf = pd.concat([soil_dxf, soil_dxf_df], ignore_index= True)\n",
    "\n",
    "    except:\n",
    "        print(i, \"no sheet found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 8 Sampling Event Screening Results_CLEAN.xlsx no sheet found\n",
      "Data Entry and QA QC Log.xlsx no sheet found\n",
      "Duwamish Puget Creek Screening Results_CLEAN.xlsx sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx no sheet found\n",
      "Kellogg Island Screening Results_CLEAN.xlsx sheet found\n",
      "People's Park Screening Result_CLEAN.xlsx sheet found\n",
      "S4 Screening Results_CLEAN.xlsx sheet found\n"
     ]
    }
   ],
   "source": [
    "# soil dioxins and furans TEQ results\n",
    "for i in results_files:\n",
    "\n",
    "    try:\n",
    "        # calculate TEQ for dioxins and furans\n",
    "        soil_dxf_teq_df = pd.read_excel(subfolder_path+'/'+i, sheet_name = 'Dioxins and Furans Soils TEQ')\n",
    "        print(i, \"sheet found\")\n",
    "\n",
    "        soil_dxf_teq_df = soil_dxf_teq_df[soil_dxf_teq_cols]\n",
    "        soil_dxf_teq_df['Analyte'] = soil_dxf_teq_df['Analyte'] + ' TEQ'\n",
    "        soil_dxf_teq_df.rename(columns = {\"Analyte\": 'variable', \"UB (mg/kg)\":\"value\"}, inplace = True)\n",
    "        soil_dxf_teq_df['Result Value Units'] = 'mg/kg'\n",
    "        soil_dxf_teq_df['Sample Matrix'] = 'Soil'\n",
    "        soil_dxf_teq_df['Measured'] = np.where(soil_dxf_teq_df['Result (ng/Kg)'].isna(), 'Upper Bound','Measured')\n",
    "        soil_dxf_teq_df['Measured'] = np.where(soil_dxf_teq_df['Result (ng/Kg)']=='ND', 'Upper Bound',soil_dxf_teq_df['Measured'])\n",
    "        soil_dxf_teq_df.drop(columns ='Result (ng/Kg)', inplace = True)\n",
    "\n",
    "        soil_dxf_teq = pd.concat([soil_dxf_teq, soil_dxf_teq_df], ignore_index= True)\n",
    "    \n",
    "    except:\n",
    "        print(i, \"no sheet found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 8 Sampling Event Screening Results_CLEAN.xlsx no sheet found\n",
      "Data Entry and QA QC Log.xlsx no sheet found\n",
      "Duwamish Puget Creek Screening Results_CLEAN.xlsx no sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx no sheet found\n",
      "Kellogg Island Screening Results_CLEAN.xlsx no sheet found\n",
      "People's Park Screening Result_CLEAN.xlsx sheet found\n",
      "S4 Screening Results_CLEAN.xlsx sheet found\n"
     ]
    }
   ],
   "source": [
    "# water dioxins and furans results\n",
    "for i in results_files:\n",
    "\n",
    "    try:\n",
    "        water_dxf_df = pd.read_excel(subfolder_path+'/'+i, sheet_name = 'Dioxins and Furans Water')\n",
    "        print(i, \"sheet found\")\n",
    "\n",
    "        water_dxf_df = water_dxf_df[water_dxf_cols]\n",
    "        water_dxf_df.rename(columns = {\"Analyte\": 'variable', \"Result (mg/Kg)\":\"value\"}, inplace = True)\n",
    "        water_dxf_df['Result Value Units'] = 'ug/L'\n",
    "        water_dxf_df['Sample Matrix'] = 'Water'\n",
    "        water_dxf = pd.concat([water_dxf, water_dxf_df], ignore_index= True)\n",
    "\n",
    "    except:\n",
    "        print(i, \"no sheet found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 8 Sampling Event Screening Results_CLEAN.xlsx no sheet found\n",
      "Data Entry and QA QC Log.xlsx no sheet found\n",
      "Duwamish Puget Creek Screening Results_CLEAN.xlsx no sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx sheet found\n",
      "Duwamish Superfund Waters_CLEAN.xlsx no sheet found\n",
      "Kellogg Island Screening Results_CLEAN.xlsx no sheet found\n",
      "People's Park Screening Result_CLEAN.xlsx sheet found\n",
      "S4 Screening Results_CLEAN.xlsx sheet found\n"
     ]
    }
   ],
   "source": [
    "# water dioxins and furans TEQ results\n",
    "for i in results_files:\n",
    "\n",
    "    try:\n",
    "        # calculate TEQ for dioxins and furans\n",
    "        water_dxf_teq_df = pd.read_excel(subfolder_path+'/'+i, sheet_name = 'Dioxins and Furans Waters TEQ')\n",
    "        print(i, \"sheet found\")\n",
    "\n",
    "        water_dxf_teq_df = water_dxf_teq_df[water_dxf_teq_cols]\n",
    "        water_dxf_teq_df['Analyte'] = water_dxf_teq_df['Analyte'] + ' TEQ'\n",
    "        water_dxf_teq_df.rename(columns = {\"Analyte\": 'variable', \"UB (ug/L)\":\"value\"}, inplace = True)\n",
    "        water_dxf_teq_df['Result Value Units'] = 'ug/L'\n",
    "        water_dxf_teq_df['Sample Matrix'] = 'Water'\n",
    "        water_dxf_teq_df['Measured'] = np.where(water_dxf_teq_df['Result (pg/L)'].isna(), 'Upper Bound','Measured')\n",
    "        water_dxf_teq_df['Measured'] = np.where(water_dxf_teq_df['Result (pg/L)']=='ND', 'Upper Bound',water_dxf_teq_df['Measured'])\n",
    "        water_dxf_teq_df.drop(columns ='Result (pg/L)', inplace = True)\n",
    "\n",
    "        water_dxf_teq = pd.concat([water_dxf_teq, water_dxf_teq_df], ignore_index= True)\n",
    "    \n",
    "    except:\n",
    "        print(i, \"no sheet found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([soil_rcra,soil_pah,soil_pcb,water_rcra, water_pah, water_pcb, soil_dxf, soil_dxf_teq, water_dxf, water_dxf_teq])\n",
    "all_results.rename(columns = {'variable': 'Result Parameter Name', 'value': 'Result Value', 'SAMP_ID': 'Sample ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.dropna(subset=['DATE'], inplace = True)\n",
    "all_results['No_Detect'] = np.where(all_results['Result Value']=='ND',1,0)\n",
    "all_results['No_Detect'] = np.where(all_results['Measured']=='Upper Bound',1,all_results['No_Detect'])\n",
    "all_results['Result Value'] = np.where(all_results['Result Value']=='ND',np.NaN,all_results['Result Value'])\n",
    "all_results['Result Value'] = np.where(all_results['Result Value']=='--',np.NaN,all_results['Result Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.to_csv(\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/duwamish/code/all_results.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN TO SCREENING LEVELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/S4 and S6 Screening Results_CLEAN.xlsx\"\n",
    "sl = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/Master_Screening_Levels.xlsx\"\n",
    "pcb_arc_lookup = pd.read_excel(results, sheet_name='PCB to Aroclor Lookup')\n",
    "\n",
    "# format pcb to aroclor loo\n",
    "pcb_arc_lookup = pcb_arc_lookup[pcb_arc_lookup['Aroclor Name'].str.contains('aroclor', na=False)][['PCB Isomer', 'Aroclor Name']]\n",
    "\n",
    "# create data frame of the screening levels for soils and\n",
    "sl_soil_df = pd.read_excel(sl, sheet_name='Soil')\n",
    "sl_water_df = pd.read_excel(sl, sheet_name='Water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace pcb names with the aroclor names to match with F&B results\n",
    "sl_soil_df_join = pd.merge(sl_soil_df, pcb_arc_lookup, how = 'outer', left_on = 'Chemical', right_on = 'PCB Isomer')\n",
    "sl_soil_df_join['Chemical'] = np.where(sl_soil_df_join['Aroclor Name'].str.contains('aroclor', na=False), sl_soil_df_join['Aroclor Name'], sl_soil_df_join['Chemical'])\n",
    "sl_soil_df_join.drop(columns = pcb_arc_lookup.columns, inplace = True)\n",
    "sl_soil_df_join = sl_soil_df_join[sl_soil_df_join['Medium']=='Soil']\n",
    "\n",
    "# replace pcb names with the aroclor names to match with F&B results\n",
    "sl_water_df_join = pd.merge(sl_water_df, pcb_arc_lookup, how = 'outer', left_on = 'Chemical', right_on = 'PCB Isomer')\n",
    "sl_water_df_join['Chemical'] = np.where(sl_water_df_join['Aroclor Name'].str.contains('aroclor', na=False), sl_water_df_join['Aroclor Name'], sl_water_df_join['Chemical'])\n",
    "sl_water_df_join.drop(columns = pcb_arc_lookup.columns, inplace = True)\n",
    "sl_water_df_join = sl_water_df_join[sl_water_df_join['Medium']=='Water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split results into soil and water\n",
    "results_soil_df = all_results[all_results['Sample Matrix'] == 'Soil']\n",
    "results_water_df = all_results[all_results['Sample Matrix'] == 'Water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join screening levels to the results\n",
    "soil_sl_join = pd.merge(sl_soil_df_join,results_soil_df,how = 'outer', left_on = ['Chemical'], right_on = ['Result Parameter Name'])\n",
    "\n",
    "# remove screening levels that do not have values\n",
    "soil_sl_join = soil_sl_join[(soil_sl_join['Screening Level Measurement']!='na')]\n",
    "soil_sl_join = soil_sl_join[(soil_sl_join['Screening Level Measurement']!='TBD')]\n",
    "soil_sl_join = soil_sl_join[(soil_sl_join['Screening Level Measurement']!='PQL')]\n",
    "soil_sl_join['Screening Level Measurement'].astype(float)\n",
    "soil_sl_join['Result Value'].astype(float)\n",
    "\n",
    "# calculate whether the screening levels have been exceeded\n",
    "soil_sl_join['SL_exceeded'] = np.where(soil_sl_join['Screening Level Measurement'] < soil_sl_join['Result Value'],'Y','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join screening levels to results\n",
    "water_sl_join = pd.merge(sl_water_df_join,results_water_df,how = 'outer', left_on = ['Chemical'], right_on = ['Result Parameter Name'])\n",
    "water_sl_join = water_sl_join[(water_sl_join['Screening Level Measurement']!='na')]\n",
    "water_sl_join = water_sl_join[(water_sl_join['Screening Level Measurement']!='TBD')]\n",
    "water_sl_join = water_sl_join[(water_sl_join['Screening Level Measurement']!='PQL')]\n",
    "water_sl_join['Screening Level Measurement'].astype(float)\n",
    "\n",
    "## TODO: make sure everything is converted correctly, including ppb / ppm\n",
    "# convert any screening levels that are in mg/L to ug/L\n",
    "water_sl_join['Screening_Level_Measurement_Convert'] = np.where(water_sl_join['SL Unit'] == 'mg/L', water_sl_join['Screening Level Measurement']*1000, water_sl_join['Screening Level Measurement'])\n",
    "water_sl_join['Screening_Level_Measurement_Convert'] = np.where(water_sl_join['SL Unit'] == 'ppm', water_sl_join['Screening Level Measurement']*1000, water_sl_join['Screening Level Measurement'])\n",
    "water_sl_join['Screening_Level_Measurement_Convert'].astype(float)\n",
    "water_sl_join['Result Value'].astype(float)\n",
    "\n",
    "# calculate whether the screening levels have been exceeded\n",
    "water_sl_join['SL_exceeded'] = np.where(water_sl_join['Screening_Level_Measurement_Convert']< water_sl_join['Result Value'], 'Y','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Medium', 'DATE','Sample ID','Chemical Group', 'Chemical', 'Result Parameter Name', 'Scenario', 'Screening Level Type',\n",
    "       'Screening Level Measurement', 'SL Unit','Result Value', 'Result Value Units', 'Source', 'SL_exceeded']\n",
    "\n",
    "all_SL_results = pd.concat([soil_sl_join[columns],water_sl_join[columns]])\n",
    "\n",
    "# where the screening level is blank, replace exceedance with \"no screening level identified\"\n",
    "all_SL_results['Screening Level Measurement'].fillna('No Screening Level Identified', inplace = True)\n",
    "all_SL_results['SL_exceeded'] = np.where(all_SL_results['Screening Level Measurement']=='No Screening Level Identified','No Screening Level Identified', all_SL_results['SL_exceeded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_SL_results.dropna(subset=['Sample ID'], inplace=True)\n",
    "all_SL_results.to_csv('/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/all_previous_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/s4_and_s6_results.csv\")\n",
    "df.rename(columns = {\"Field Collection Start Date\": 'DATE'}, inplace = True)\n",
    "df_upd = pd.concat([all_SL_results,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_upd.to_excel(\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/all_results_for_tableau.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4605/3924950913.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_upd_trim['SL_diff'] = df_upd_trim['Result Value'] - df_upd_trim['Screening Level Measurement'].astype(float)\n"
     ]
    }
   ],
   "source": [
    "# calculate difference between screening levels and measured results\n",
    "df_upd_trim = df_upd[df_upd['Screening Level Measurement']!='No Screening Level Identified']\n",
    "df_upd_trim['SL_diff'] = df_upd_trim['Result Value'] - df_upd_trim['Screening Level Measurement'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATE MOST STRINGENT AND COUNT OF ALL SCREENING LEVELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sl = pd.concat([sl_soil_df_join, sl_water_df_join])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sl['Screening Level Measurement'] = np.where(all_sl['Screening Level Measurement']=='na', np.NaN, all_sl['Screening Level Measurement'])\n",
    "all_sl['Screening Level Measurement'] = np.where(all_sl['Screening Level Measurement'] == 'na', np.NaN, all_sl['Screening Level Measurement'])\n",
    "all_sl['Screening Level Measurement'] = np.where(all_sl['Screening Level Measurement'] == 'TBD', np.NaN, all_sl['Screening Level Measurement'])\n",
    "all_sl['Screening Level Measurement'] = np.where(all_sl['Screening Level Measurement'] == 'PQL', np.NaN, all_sl['Screening Level Measurement'])\n",
    "\n",
    "all_sl['Screening Level Measurement'] = all_sl['Screening Level Measurement'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringent = all_sl.groupby(by =['Medium', 'Chemical Group', 'Chemical', 'Scenario']).agg({'Screening Level Measurement': ['max']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringent.reset_index(inplace = True)\n",
    "stringent.columns = stringent.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df_upd and stringent\n",
    "stringent_merge = stringent.merge(df_upd, left_on = ['Medium', 'Chemical Group', 'Chemical', 'Scenario', 'Screening Level Measurement'], right_on = ['Medium', 'Chemical Group', 'Chemical', 'Scenario', 'Screening Level Measurement'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4605/3714314168.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stringent_merge_exceed['SL_diff'] = stringent_merge_exceed['Screening Level Measurement'] - stringent_merge_exceed['Result Value']\n"
     ]
    }
   ],
   "source": [
    "stringent_merge_exceed = stringent_merge[stringent_merge['SL_exceeded']=='Y']\n",
    "stringent_merge_exceed['SL_diff'] = stringent_merge_exceed['Screening Level Measurement'] - stringent_merge_exceed['Result Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE COUNT EXCEEDANCES COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_sl = all_sl.groupby(by =['Medium', 'Chemical Group', 'Chemical', 'Scenario']).agg({'Screening Level Measurement': ['count']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_sl.reset_index(inplace = True)\n",
    "cnt_sl.columns = cnt_sl.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_exceedances = df_upd[df_upd['SL_exceeded']=='Y'].groupby(by =['Medium', 'Sample ID', 'Chemical Group', 'Chemical', 'Scenario']).agg({'SL_exceeded': ['count']}).reset_index()\n",
    "cnt_exceedances.reset_index(inplace = True)\n",
    "cnt_exceedances.columns = cnt_exceedances.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_exceedances_merge = cnt_exceedances.merge(cnt_sl, left_on = ['Medium', 'Chemical Group', 'Chemical', 'Scenario'], right_on = ['Medium', 'Chemical Group', 'Chemical', 'Scenario'])\n",
    "cnt_exceedances_merge['pct_SL_exceeded'] = cnt_exceedances_merge['SL_exceeded'] / cnt_exceedances_merge['Screening Level Measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_exceedances_merge.drop(columns = ['index_x', 'index_y'], inplace = True)\n",
    "cnt_exceedances_merge.rename(columns = {'SL_exceeded':'cnt_SL_exceeded', 'Screening Level Measurement':'tot_cnt_SL'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORT FOR MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all exceedance results with differences between results and screening levels\n",
    "df_upd_trim = df_upd_trim[df_upd_trim['SL_exceeded']=='Y']\n",
    "df_upd_trim.to_csv(\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/exceedances_w_difference.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results that only exceed most stringent screening levels\n",
    "stringent_merge_exceed.to_csv(\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/stringent_exceeded.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results based on count of exceedances and for each results\n",
    "cnt_exceedances_merge.to_csv(\"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/count_exceedances.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
