{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate file names for output results\n",
    "current_results_file = f\"nov23_results_joined_SL_{date.today().strftime('%Y%m%d')}\"\n",
    "all_results_file = f\"all_results_joined_SL_{date.today().strftime('%Y%m%d')}\"\n",
    "\n",
    "# initate folder paths for data to read in\n",
    "folder_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12\"\n",
    "prev_results = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/all_results_joined_SL_20231214.csv\"\n",
    "sl = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/Master_Screening_Levels.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/311115 SGS EDD.xlsx\n",
      "<DatetimeArray>\n",
      "['NaT', '2023-11-07 00:00:00']\n",
      "Length: 2, dtype: datetime64[ns]\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/311175 SGS EDD Soil.xlsx\n",
      "<DatetimeArray>\n",
      "['NaT', '2023-11-08 00:00:00']\n",
      "Length: 2, dtype: datetime64[ns]\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/311175 SGS EDD water.xlsx\n",
      "<DatetimeArray>\n",
      "['NaT', '2023-11-08 00:00:00']\n",
      "Length: 2, dtype: datetime64[ns]\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/B8755_EDD.xlsx\n",
      "<DatetimeArray>\n",
      "['NaT', '2023-11-07 00:00:00']\n",
      "Length: 2, dtype: datetime64[ns]\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/University of Washington Bothell Duwamish RCN 311018 EIM.xlsx\n",
      "<DatetimeArray>\n",
      "['2023-11-01 00:00:00']\n",
      "Length: 1, dtype: datetime64[ns]\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/University of Washington Bothell Duwamish RCN 311115 EIM.xlsx\n",
      "<DatetimeArray>\n",
      "['2023-11-17 00:00:00']\n",
      "Length: 1, dtype: datetime64[ns]\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/University of Washington Bothell UW (IAS) 311175 EIM.xlsx\n",
      "<DatetimeArray>\n",
      "['2023-11-08 00:00:00']\n",
      "Length: 1, dtype: datetime64[ns]\n",
      "2210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['NaT', '2023-11-01 00:00:00', '2023-11-17 00:00:00', '2023-11-08 00:00:00']\n",
       "Length: 4, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_extension = '*.xlsx'\n",
    "\n",
    "# List all files with the specified extension in the folder\n",
    "files = glob.glob(os.path.join(folder_path, file_extension))\n",
    "\n",
    "results_df = []\n",
    "# Iterate through each file and read its content\n",
    "for file_path in files:\n",
    "    print(file_path)\n",
    "    df = pd.read_excel(file_path)\n",
    "    try:\n",
    "        print(df['Field_Collection_Start_Date'].unique())\n",
    "    except:\n",
    "        print(df['Field Collection Start Date'].unique())\n",
    "    results_df.append(df)\n",
    "\n",
    "results_df = pd.concat(results_df)\n",
    "print(len(results_df))\n",
    "results_df['Field Collection Start Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any rows without a sample ID\n",
    "results_df =  results_df[results_df['Sample ID'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change sample ID DPS1 -> DPS-1\n",
    "results_df['Sample ID'] = np.where(results_df['Sample ID'] == 'DPS1', 'DPS-1', results_df['Sample ID'])\n",
    "\n",
    "# change sample ID SPB-0159-S-1 -> SPB-O159-S-1\n",
    "results_df['Sample ID'] = np.where(results_df['Sample ID'] == 'SPB-0159-S-1', 'SPB-O159-S-1', results_df['Sample ID'])\n",
    "\n",
    "# remove trailing spaces in sample id\n",
    "results_df['Sample ID'] = results_df['Sample ID'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2023-11-01 00:00:00', '2023-11-17 00:00:00', '2023-11-08 00:00:00']\n",
       "Length: 3, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Field Collection Start Date'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN TABLES OF RESULTS TO MASTER SCREENING LEVELS FROM F&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in screening results and master screening level spreadsheets\n",
    "S4_S6_results = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/S4 and S6 Screening Results_CLEAN.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frames of the raw data and the lookup\n",
    "S4_S6_results_df = pd.read_excel(S4_S6_results, sheet_name='RAW_DATA')\n",
    "pcb_arc_lookup = pd.read_excel(S4_S6_results, sheet_name='PCB to Aroclor Lookup')\n",
    "\n",
    "# create data frame of the screening levels for soils and\n",
    "sl_soil_df = pd.read_excel(sl, sheet_name='Soil')\n",
    "sl_water_df = pd.read_excel(sl, sheet_name='Water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format pcb to aroclor loo\n",
    "pcb_arc_lookup = pcb_arc_lookup[pcb_arc_lookup['Aroclor Name'].str.contains('aroclor', na=False)][['PCB Isomer', 'Aroclor Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace pcb names with the aroclor names to match with F&B results\n",
    "sl_soil_df_join = pd.merge(sl_soil_df, pcb_arc_lookup, how = 'outer', left_on = 'Chemical', right_on = 'PCB Isomer')\n",
    "sl_soil_df_join['Chemical'] = np.where(sl_soil_df_join['Aroclor Name'].str.contains('aroclor', na=False), sl_soil_df_join['Aroclor Name'], sl_soil_df_join['Chemical'])\n",
    "sl_soil_df_join.drop(columns = pcb_arc_lookup.columns, inplace = True)\n",
    "sl_soil_df_join = sl_soil_df_join[sl_soil_df_join['Medium']=='Soil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace pcb names with the aroclor names to match with F&B results\n",
    "sl_water_df_join = pd.merge(sl_water_df, pcb_arc_lookup, how = 'outer', left_on = 'Chemical', right_on = 'PCB Isomer')\n",
    "sl_water_df_join['Chemical'] = np.where(sl_water_df_join['Aroclor Name'].str.contains('aroclor', na=False), sl_water_df_join['Aroclor Name'], sl_water_df_join['Chemical'])\n",
    "sl_water_df_join.drop(columns = pcb_arc_lookup.columns, inplace = True)\n",
    "sl_water_df_join = sl_water_df_join[sl_water_df_join['Medium']=='Water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns from raw data\n",
    "results_df = results_df[['Sample ID','Field Collection Start Date','Sample Matrix','Sample Source','Result Parameter Name','Result Value',\n",
    "       'Result Value Units', 'Result Reporting Limit',\n",
    "       'Result Reporting Limit Type', 'Result Detection Limit',\n",
    "       'Result Detection Limit Type', 'Result Data Qualifier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2023-11-01 00:00:00', '2023-11-17 00:00:00', '2023-11-08 00:00:00']\n",
       "Length: 3, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Field Collection Start Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split results into soil and water\n",
    "results_soil_df = results_df[results_df['Sample Source']=='Soil']\n",
    "results_water_df = results_df[results_df['Sample Matrix']=='Water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2023-11-01 00:00:00', '2023-11-17 00:00:00', '2023-11-08 00:00:00']\n",
       "Length: 3, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_soil_df['Field Collection Start Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join screening levels to the results\n",
    "soil_sl_join = pd.merge(sl_soil_df_join,results_soil_df,how = 'outer', left_on = ['Chemical'], right_on = ['Result Parameter Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2023-11-01 00:00:00', '2023-11-17 00:00:00', '2023-11-08 00:00:00', 'NaT']\n",
       "Length: 4, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_sl_join['Field Collection Start Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.77\n",
       "1       0.77\n",
       "2       0.77\n",
       "3       0.77\n",
       "4       0.77\n",
       "        ... \n",
       "3105     NaN\n",
       "3106     NaN\n",
       "3107     NaN\n",
       "3108     NaN\n",
       "3109     NaN\n",
       "Name: Screening Level Measurement, Length: 2413, dtype: float64"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove screening levels that do not have values\n",
    "soil_sl_join = soil_sl_join[(soil_sl_join['Screening Level Measurement']!='na')]\n",
    "soil_sl_join = soil_sl_join[(soil_sl_join['Screening Level Measurement']!='TBD')]\n",
    "soil_sl_join = soil_sl_join[(soil_sl_join['Screening Level Measurement']!='PQL')]\n",
    "soil_sl_join['Screening Level Measurement'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate whether the screening levels have been exceeded\n",
    "soil_sl_join['SL_exceeded'] = np.where(soil_sl_join['Screening Level Measurement'] <soil_sl_join['Result Value'],'Y','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2023-11-01 00:00:00', '2023-11-17 00:00:00', '2023-11-08 00:00:00', 'NaT']\n",
       "Length: 4, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_sl_join['Field Collection Start Date'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join screening levels to results\n",
    "water_sl_join = pd.merge(sl_water_df_join,results_water_df,how = 'outer', left_on = ['Chemical'], right_on = ['Result Parameter Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000052\n",
       "1       0.000052\n",
       "2       0.000052\n",
       "3       0.000052\n",
       "4       0.009700\n",
       "          ...   \n",
       "1813         NaN\n",
       "1814         NaN\n",
       "1815         NaN\n",
       "1816         NaN\n",
       "1817         NaN\n",
       "Name: Screening Level Measurement, Length: 1691, dtype: float64"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_sl_join = water_sl_join[(water_sl_join['Screening Level Measurement']!='na')]\n",
    "water_sl_join = water_sl_join[(water_sl_join['Screening Level Measurement']!='TBD')]\n",
    "water_sl_join = water_sl_join[(water_sl_join['Screening Level Measurement']!='PQL')]\n",
    "water_sl_join['Screening Level Measurement'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert any screening levels that are in mg/L to ug/L\n",
    "water_sl_join[water_sl_join['SL Unit'] == 'mg/L']\n",
    "\n",
    "water_sl_join['Screening_Level_Measurement_Convert'] = np.where(water_sl_join['SL Unit'] == 'mg/L', water_sl_join['Screening Level Measurement']*1000, water_sl_join['Screening Level Measurement'])\n",
    "water_sl_join['Screening_Level_Measurement_Convert'] = np.where(water_sl_join['SL Unit'] == 'ppm', water_sl_join['Screening Level Measurement']*1000, water_sl_join['Screening Level Measurement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate whether the screening levels have been exceeded\n",
    "water_sl_join['SL_exceeded'] = np.where(water_sl_join['Screening_Level_Measurement_Convert']< water_sl_join['Result Value'], 'Y','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Medium', 'Sample ID','Field Collection Start Date', 'Chemical Group', 'Chemical', 'Result Parameter Name', 'Scenario', 'Screening Level Type',\n",
    "       'Screening Level Measurement', 'Result Value', 'Result Data Qualifier', 'SL Unit', 'Source', 'SL_exceeded']\n",
    "\n",
    "all_results = pd.concat([soil_sl_join[columns],water_sl_join[columns]])\n",
    "all_results['SL_diff'] = all_results['Result Value'] - all_results['Screening Level Measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the screening level is blank, replace exceedance with \"no screening level identified\"\n",
    "all_results['Screening Level Measurement'].fillna('No Screening Level Identified', inplace = True)\n",
    "all_results['SL_exceeded'] = np.where(all_results['Screening Level Measurement']=='No Screening Level Identified','No Screening Level Identified', all_results['SL_exceeded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.dropna(subset=['Sample ID'], inplace=True)\n",
    "all_results.rename(columns = {'Field Collection Start Date': 'DATE'}, inplace = True)\n",
    "all_results.to_csv(f'/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/{current_results_file }.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN TO PREVIOUS SCREENING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to previous results\n",
    "prev_results_df= pd.read_csv(prev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_df = pd.concat([prev_results_df, all_results])\n",
    "all_results_df.to_csv(f'/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/{all_results_file}.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
