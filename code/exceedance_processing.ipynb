{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate file names for output results\n",
    "current_results_file = f\"nov23_results_joined_SL_{date.today().strftime('%Y%m%d')}\"\n",
    "all_results_file = f\"all_results_joined_SL_{date.today().strftime('%Y%m%d')}\"\n",
    "\n",
    "# initate folder paths for data to read in\n",
    "folder_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12\"\n",
    "prev_results = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/all_results_joined_SL_20231214.csv\"\n",
    "sl_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/Master_Screening_Levels.xlsx\"\n",
    "pcb_arc_lookup_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/PCB_aroclor_lookup.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS RESULTS SPREADSHEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/311115 SGS EDD.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/311175 SGS EDD Soil.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/311175 SGS EDD water.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/B8755_EDD.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/University of Washington Bothell Duwamish RCN 311018 EIM.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/University of Washington Bothell Duwamish RCN 311115 EIM.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/University of Washington Bothell UW (IAS) 311175 EIM.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/UWB UW IAS 312067 EIM.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/UWB UW IAS 312117 EIM.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/UWB UW IAS 312084 EIM.xlsx\n",
      "2620\n"
     ]
    }
   ],
   "source": [
    "file_extension = '*.xlsx'\n",
    "\n",
    "# List all files with the specified extension in the folder\n",
    "files = glob.glob(os.path.join(folder_path, file_extension))\n",
    "\n",
    "results_df = []\n",
    "length = 0\n",
    "# Iterate through each file and read its content\n",
    "for file_path in files:\n",
    "    print(file_path)\n",
    "    df = pd.read_excel(file_path)\n",
    "    df.columns = df.columns.str.replace(\"_\",\" \")\n",
    "    results_df.append(df)\n",
    "\n",
    "results_df = pd.concat(results_df)\n",
    "print(len(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1720"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove any rows that were not field data\n",
    "results_df =  results_df[results_df['Field Collection Start Date'].isna() == False]\n",
    "len(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aqueous' 'Solid' 'Solid/Sediment' 'Water']\n",
      "[nan 'Soil' 'Groundwater']\n"
     ]
    }
   ],
   "source": [
    "print(results_df['Sample Matrix'].unique())\n",
    "print(results_df['Sample Source'].unique())\n",
    "\n",
    "# create new column of sample type based on sample matrix and sample source columns\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Matrix']=='Aqueous', 'Water', results_df['Sample Matrix'])\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Matrix'].str.contains('Solid'), 'Soil', results_df['Sample Matrix_clean'])\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Source']=='Groundwater', 'Water', results_df['Sample Matrix_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: come back and figure out the PCBs with multiple numbers and make sure they are the right chemical name\n",
    "# remove leading PCB-### from result parameter name to match screening level spreadsheet\n",
    "\n",
    "def clean_fun(val):\n",
    "    if 'PCB' in val:\n",
    "        if 'aroclor' not in val:\n",
    "            if '...' in val:\n",
    "                return 'FLAG'\n",
    "            list = val.split(' ')\n",
    "            if len(list)>1:\n",
    "                return list[1]\n",
    "            else:\n",
    "                return 'FLAG'\n",
    "    return val\n",
    "\n",
    "results_df['Result Parameter Name'] = results_df['Result Parameter Name'].apply(lambda x: clean_fun(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trailing spaces in sample id\n",
    "results_df['Sample ID'] = results_df['Sample ID'].str.strip()\n",
    "\n",
    "# change sample ID DPS1 -> DPS-1\n",
    "results_df['Sample ID'] = np.where(results_df['Sample ID'] == 'DPS1', 'DPS-1', results_df['Sample ID'])\n",
    "\n",
    "# change sample ID SPB-0159-S-1 -> SPB-O159-S-1\n",
    "results_df['Sample ID'] = np.where(results_df['Sample ID'] == 'SPB-0159-S-1', 'SPB-O159-S-1', results_df['Sample ID'])\n",
    "\n",
    "# replace typo from 11/17 -> 11/07\n",
    "results_df['Field Collection Start Date'] = np.where(results_df['Field Collection Start Date']=='2023-11-17 00:00:00', np.datetime64('2023-11-07'), results_df['Field Collection Start Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns from raw data\n",
    "results_df = results_df[['Sample ID','Field Collection Start Date','Sample Matrix','Sample Source','Result Parameter Name','Result Value',\n",
    "       'Result Value Units', 'Result Reporting Limit',\n",
    "       'Result Reporting Limit Type', 'Result Detection Limit',\n",
    "       'Result Detection Limit Type', 'Result Data Qualifier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split results into soil and water\n",
    "results_soil_df = results_df[results_df['Sample Matrix_clean']=='Soil']\n",
    "results_water_df = results_df[results_df['Sample Matrix_clean']=='Water']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN TABLES OF RESULTS TO MASTER SCREENING LEVELS FROM F&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frames of the raw data and the lookup\n",
    "pcb_arc_lookup = pd.read_csv(pcb_arc_lookup_path)\n",
    "\n",
    "# create data frame of the screening levels for soils and\n",
    "sl_soil_df = pd.read_excel(sl_path, sheet_name='Soil')\n",
    "sl_water_df = pd.read_excel(sl_path, sheet_name='Water')\n",
    "\n",
    "# concatenate to all screening levels\n",
    "sl = pd.concat([sl_soil_df, sl_water_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip dioxin furans screening levels of their commas to match the results spreadsheet\n",
    "sl_soil_df['Chemical'] = np.where(sl_soil_df['Chemical Group']== 'Dioxin Furans', sl_soil_df['Chemical'].str.replace(',',''), sl_soil_df['Chemical'])\n",
    "sl_water_df['Chemical'] = np.where(sl_water_df['Chemical Group']== 'Dioxin Furans', sl_water_df['Chemical'].str.replace(',',''), sl_water_df['Chemical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip pcbs of their commas to match the results spreadsheet\n",
    "sl_soil_df['Chemical'] = np.where(sl_soil_df['Chemical Group']== 'PCB', sl_soil_df['Chemical'].str.replace(',',''), sl_soil_df['Chemical'])\n",
    "sl_water_df['Chemical'] = np.where(sl_water_df['Chemical Group']== 'PCB', sl_water_df['Chemical'].str.replace(',',''), sl_water_df['Chemical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format pcb to aroclor loo\n",
    "pcb_arc_lookup = pcb_arc_lookup[pcb_arc_lookup['Aroclor Name'].str.contains('aroclor', na=False)][['PCB Isomer', 'Aroclor Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN SCREENING LEVELS TO RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace pcb names with the aroclor names to match with F&B results\n",
    "sl_soil_df_join = pd.merge(sl_soil_df, pcb_arc_lookup, how = 'outer', left_on = 'Chemical', right_on = 'PCB Isomer')\n",
    "sl_soil_df_join['Chemical'] = np.where(sl_soil_df_join['Aroclor Name'].str.contains('aroclor', na=False), sl_soil_df_join['Aroclor Name'], sl_soil_df_join['Chemical'])\n",
    "sl_soil_df_join.drop(columns = pcb_arc_lookup.columns, inplace = True)\n",
    "sl_soil_df_join = sl_soil_df_join[sl_soil_df_join['Medium']=='Soil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace pcb names with the aroclor names to match with F&B results\n",
    "sl_water_df_join = pd.merge(sl_water_df, pcb_arc_lookup, how = 'outer', left_on = 'Chemical', right_on = 'PCB Isomer')\n",
    "sl_water_df_join['Chemical'] = np.where(sl_water_df_join['Aroclor Name'].str.contains('aroclor', na=False), sl_water_df_join['Aroclor Name'], sl_water_df_join['Chemical'])\n",
    "sl_water_df_join.drop(columns = pcb_arc_lookup.columns, inplace = True)\n",
    "sl_water_df_join = sl_water_df_join[sl_water_df_join['Medium']=='Water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join screening levels to the results\n",
    "soil_sl_join = pd.merge(sl_soil_df_join,results_soil_df,how = 'outer', left_on = ['Chemical'], right_on = ['Result Parameter Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove screening levels that do not have values\n",
    "soil_sl_join = soil_sl_join[(soil_sl_join['Screening Level Measurement']!='na')]\n",
    "soil_sl_join = soil_sl_join[(soil_sl_join['Screening Level Measurement']!='TBD')]\n",
    "soil_sl_join = soil_sl_join[(soil_sl_join['Screening Level Measurement']!='PQL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate whether the screening levels have been exceeded\n",
    "soil_sl_join['SL_exceeded'] = np.where(soil_sl_join['Screening Level Measurement'] <soil_sl_join['Result Value'],'Y','N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN SCREENING LEVELS TO RESULTS - WATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join screening levels to results\n",
    "water_sl_join = pd.merge(sl_water_df_join,results_water_df,how = 'outer', left_on = ['Chemical'], right_on = ['Result Parameter Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_sl_join = water_sl_join[(water_sl_join['Screening Level Measurement']!='na')]\n",
    "water_sl_join = water_sl_join[(water_sl_join['Screening Level Measurement']!='TBD')]\n",
    "water_sl_join = water_sl_join[(water_sl_join['Screening Level Measurement']!='PQL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert any screening levels that are in mg/L to ug/L\n",
    "water_sl_join[water_sl_join['SL Unit'] == 'mg/L']\n",
    "\n",
    "water_sl_join['Screening_Level_Measurement_Convert'] = np.where(water_sl_join['SL Unit'] == 'mg/L', water_sl_join['Screening Level Measurement']*1000, water_sl_join['Screening Level Measurement'])\n",
    "water_sl_join['Screening_Level_Measurement_Convert'] = np.where(water_sl_join['SL Unit'] == 'ppm', water_sl_join['Screening Level Measurement']*1000, water_sl_join['Screening Level Measurement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate whether the screening levels have been exceeded\n",
    "water_sl_join['SL_exceeded'] = np.where(water_sl_join['Screening_Level_Measurement_Convert']< water_sl_join['Result Value'], 'Y','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Medium', 'Sample ID','Field Collection Start Date', 'Chemical Group', 'Chemical', 'Result Parameter Name', 'Scenario', 'Screening Level Type',\n",
    "       'Screening Level Measurement', 'Result Value', 'Result Data Qualifier', 'SL Unit', 'Source', 'SL_exceeded']\n",
    "\n",
    "all_results = pd.concat([soil_sl_join[columns],water_sl_join[columns]])\n",
    "all_results['SL_diff'] = all_results['Result Value'] - all_results['Screening Level Measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the screening level is blank, replace exceedance with \"no screening level identified\"\n",
    "all_results['Screening Level Measurement'].fillna('No Screening Level Identified', inplace = True)\n",
    "all_results['SL_exceeded'] = np.where(all_results['Screening Level Measurement']=='No Screening Level Identified','No Screening Level Identified', all_results['SL_exceeded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.dropna(subset=['Sample ID'], inplace=True)\n",
    "all_results.rename(columns = {'Field Collection Start Date': 'DATE'}, inplace = True)\n",
    "all_results.to_csv(f'/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/{current_results_file}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN TO PREVIOUS SCREENING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to previous results\n",
    "prev_results_df= pd.read_csv(prev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_results_df = pd.concat([prev_results_df, all_results])\n",
    "all_results.to_csv(f'/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/{all_results_file}.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
