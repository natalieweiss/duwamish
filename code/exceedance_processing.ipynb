{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate file names for output results\n",
    "current_results_file = f\"nov23_results_joined_SL_{date.today().strftime('%Y%m%d')}\"\n",
    "all_results_file = f\"all_results_joined_SL_{date.today().strftime('%Y%m%d')}\"\n",
    "\n",
    "# initate folder paths for data to read in\n",
    "folder_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12\"\n",
    "prev_results = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/all_results_joined_SL_20231214.csv\"\n",
    "sl_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/Master_Screening_Levels.xlsx\"\n",
    "pcb_arc_lookup_path = \"/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/PCB_aroclor_lookup.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS RESULTS SPREADSHEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/311115 SGS EDD.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/311175 SGS EDD Soil.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/311175 SGS EDD water.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/B8755_EDD.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/University of Washington Bothell Duwamish RCN 311018 EIM.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/University of Washington Bothell Duwamish RCN 311115 EIM.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/University of Washington Bothell UW (IAS) 311175 EIM.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/UWB UW IAS 312067 EIM.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/UWB UW IAS 312117 EIM.xlsx\n",
      "/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/2023 Screening Results/2023.12/UWB UW IAS 312084 EIM.xlsx\n",
      "2620\n"
     ]
    }
   ],
   "source": [
    "file_extension = '*.xlsx'\n",
    "\n",
    "# List all files with the specified extension in the folder\n",
    "files = glob.glob(os.path.join(folder_path, file_extension))\n",
    "\n",
    "results_df = []\n",
    "length = 0\n",
    "# Iterate through each file and read its content\n",
    "for file_path in files:\n",
    "    print(file_path)\n",
    "    df = pd.read_excel(file_path)\n",
    "    df.columns = df.columns.str.replace(\"_\",\" \")\n",
    "    results_df.append(df)\n",
    "\n",
    "results_df = pd.concat(results_df)\n",
    "print(len(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1720"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove any rows that were not field data\n",
    "results_df =  results_df[results_df['Field Collection Start Date'].isna() == False]\n",
    "len(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aqueous' 'Solid' 'Solid/Sediment' 'Water']\n",
      "[nan 'Soil' 'Groundwater']\n"
     ]
    }
   ],
   "source": [
    "print(results_df['Sample Matrix'].unique())\n",
    "print(results_df['Sample Source'].unique())\n",
    "\n",
    "# create new column of sample type based on sample matrix and sample source columns\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Matrix']=='Aqueous', 'Water', results_df['Sample Matrix'])\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Matrix'].str.contains('Solid'), 'Soil', results_df['Sample Matrix_clean'])\n",
    "results_df['Sample Matrix_clean'] = np.where(results_df['Sample Source']=='Groundwater', 'Water', results_df['Sample Matrix_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: come back and figure out the PCBs with multiple numbers and make sure they are the right chemical name\n",
    "# remove leading PCB-### from result parameter name to match screening level spreadsheet\n",
    "\n",
    "def clean_fun(val):\n",
    "    if 'PCB' in val:\n",
    "        val = val.replace(\"/\",\" \").split(\" \")[0]\n",
    "    return val\n",
    "\n",
    "results_df['Result Parameter Name_clean'] = results_df['Result Parameter Name'].apply(lambda x: clean_fun(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trailing spaces in sample id\n",
    "results_df['Sample ID'] = results_df['Sample ID'].str.strip()\n",
    "\n",
    "# change sample ID DPS1 -> DPS-1\n",
    "results_df['Sample ID'] = np.where(results_df['Sample ID'] == 'DPS1', 'DPS-1', results_df['Sample ID'])\n",
    "\n",
    "# change sample ID SPB-0159-S-1 -> SPB-O159-S-1\n",
    "results_df['Sample ID'] = np.where(results_df['Sample ID'] == 'SPB-0159-S-1', 'SPB-O159-S-1', results_df['Sample ID'])\n",
    "\n",
    "# replace typo from 11/17 -> 11/07\n",
    "results_df['Field Collection Start Date'] = np.where(results_df['Field Collection Start Date']=='2023-11-17 00:00:00', np.datetime64('2023-11-07'), results_df['Field Collection Start Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns from raw data\n",
    "results_df = results_df[['Sample ID','Field Collection Start Date','Sample Matrix_clean','Sample Matrix','Sample Source',\n",
    "                         'Result Parameter Name','Result Parameter Name_clean','Result Value', 'Result Value Units', 'Result Reporting Limit', \n",
    "                         'Result Reporting Limit Type', 'Result Detection Limit','Result Detection Limit Type', 'Result Data Qualifier']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN TABLES OF RESULTS TO MASTER SCREENING LEVELS FROM F&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame of the screening levels for soils and\n",
    "sl_soil_df = pd.read_excel(sl_path, sheet_name='Soil')\n",
    "sl_water_df = pd.read_excel(sl_path, sheet_name='Water')\n",
    "\n",
    "# concatenate to all screening levels\n",
    "sl = pd.concat([sl_soil_df, sl_water_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip dioxin furans screening levels of their commas to match the results spreadsheet\n",
    "sl['Chemical'] = np.where(sl['Chemical Group']== 'Dioxin Furans', sl['Chemical'].str.replace(',',''), sl['Chemical'])\n",
    "\n",
    "# strip pcbs of their commas to match the results spreadsheet\n",
    "sl['Chemical'] = np.where(sl['Chemical Group']== 'PCB', sl['Chemical'].str.replace(',',''), sl['Chemical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN SCREENING LEVELS TO RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frames of the raw data and the lookup\n",
    "pcb_arc_lookup = pd.read_csv(pcb_arc_lookup_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcb_arc_lookup['PCB Isomer'] = pcb_arc_lookup['PCB Isomer'].str.replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace pcb names with the aroclor names to match with F&B results\n",
    "sl_arc_join = pd.merge(sl, pcb_arc_lookup, how = 'outer', left_on = 'Chemical', right_on = 'PCB Isomer')\n",
    "sl_arc_join['Chemical'] = np.where(sl_arc_join['Aroclor Name'].str.contains('aroclor', na=False),sl_arc_join['Aroclor Name'], sl_arc_join['Chemical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join screening levels to the results\n",
    "sl_results_join = pd.merge(sl_arc_join,results_df,how = 'outer', left_on = ['Chemical'], right_on = ['Result Parameter Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove screening levels that do not have values\n",
    "sl_results_join = sl_results_join[(sl_results_join['Screening Level Measurement']!='na')]\n",
    "sl_results_join = sl_results_join[(sl_results_join['Screening Level Measurement']!='TBD')]\n",
    "sl_results_join = sl_results_join[(sl_results_join['Screening Level Measurement']!='PQL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate whether the screening levels have been exceeded\n",
    "sl_results_join['SL_exceeded'] = np.where(sl_results_join['Screening Level Measurement'] < sl_results_join['Result Value'],'Y','N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''columns = ['Medium', 'Sample ID','Field Collection Start Date', 'Chemical Group', 'Chemical', 'Result Parameter Name', 'Scenario', 'Screening Level Type',\n",
    "       'Screening Level Measurement', 'Result Value', 'Result Data Qualifier', 'SL Unit', 'Source', 'SL_exceeded']\n",
    "'''\n",
    "\n",
    "sl_results_join['SL_diff'] = sl_results_join['Result Value'] - sl_results_join['Screening Level Measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the screening level is blank, replace exceedance with \"no screening level identified\"\n",
    "sl_results_join['Screening Level Measurement'].fillna('No Screening Level Identified', inplace = True)\n",
    "sl_results_join['SL_exceeded'] = np.where(sl_results_join['Screening Level Measurement']=='No Screening Level Identified','No Screening Level Identified', sl_results_join['SL_exceeded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_results_join.dropna(subset=['Sample ID'], inplace=True)\n",
    "sl_results_join.rename(columns = {'Field Collection Start Date': 'DATE'}, inplace = True)\n",
    "sl_results_join.to_csv(f'/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/{current_results_file}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN TO PREVIOUS SCREENING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to previous results\n",
    "prev_results_df= pd.read_csv(prev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_df = pd.concat([prev_results_df, sl_results_join])\n",
    "all_results_df.to_csv(f'/home/nweiss/gdrive/Year 2/Summer - Duwamish/Sampling_Results/{all_results_file}.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
